<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="LongVU">

  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Vision-Language Model, Multi-modal LLM, Spatial-Temporal Understanding">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>LongVU</title>
  <link rel="icon" type="image/x-icon" href="static/images/icon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-five-sixths">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">LongVU: Spatiotemporal Adaptive Compression for Long Video-Language Understanding</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <a href="https://xiaoqian-shen.github.io/" style="color:#008AD7;font-weight:normal;">Xiaoqian Shen</a><sup style="color:#ed4b82;">1,</sup><sup style="color:#6fbf73;">2</sup>,</span>
              <a href="https://scholar.google.com/citations?user=k5FaRwcAAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Yunyang Xiong</a><sup style="color:#6fbf73;">2</sup>,</span>
              <a href="https://scholar.google.com/citations?user=bXnrlyAAAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Changsheng Zhao</a><sup style="color:#6fbf73;">2</sup>,</span>
              <a href="https://scholar.google.ca/citations?user=PCDSl2sAAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Lemeng Wu</a><sup style="color:#6fbf73;">2</sup>,</span>
              <a href="https://scholar.google.com/citations?user=9G2OQmkAAAAJ&hl=en&oi=ao" style="color:#008AD7;font-weight:normal;">Jun Chen</a><sup style="color:#ed4b82;">1</sup>,</span>
              <a href="https://scholar.google.com/citations?user=MlyN118AAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Chenchen Zhu</a><sup style="color:#6fbf73;">2</sup>,</span>
              <a href="https://scholar.google.com/citations?user=lA7ylt4AAAAJ&hl=zh-CN" style="color:#008AD7;font-weight:normal;">Zechun Liu</a><sup style="color:#6fbf73;">2</sup>,</span>
              <a href="https://scholar.google.com/citations?user=cuqP0dYAAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Fanyi Xiao</a><sup style="color:#6fbf73;">2</sup>,</span>
              <a href="https://scholar.google.com/citations?user=fCqk928AAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Balakrishnan Varadarajan</a><sup style="color:#6fbf73;">2</sup>,</span>
              <a href="https://scholar.google.com/citations?user=OADfWhUAAAAJ" style="color:#008AD7;font-weight:normal;">Florian Bordes</a><sup style="color:#6fbf73;">2</sup>,</span>
              <a href="https://scholar.google.com/citations?user=7OTD-LEAAAAJ" style="color:#008AD7;font-weight:normal;">Zhuang Liu</a><sup style="color:#6fbf73;">2</sup>,</span>
              <a href="https://scholar.google.com/citations?user=SaH2yWMAAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Hu Xu</a><sup style="color:#6fbf73;">2</sup>,</span>
              <a href="https://scholar.google.com/citations?user=LfBoJt8AAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Hyunwoo J. Kim</a><sup style="color:#ffac33;">3</sup>,</span>
              <a href="https://openreview.net/profile?id=~Bilge_Soran1" style="color:#008AD7;font-weight:normal;">Bilge Soran</a><sup style="color:#6fbf73;">2</sup>,</span>
              <a href="https://scholar.google.com/citations?user=F1mr9C0AAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Raghuraman Krishnamoorthi</a><sup style="color:#6fbf73;">2</sup>,</span>
              <a href="https://scholar.google.com/citations?user=iRBUTOAAAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Mohamed Elhoseiny</a><sup style="color:#ed4b82;">1</sup>,</span>
              <a href="https://scholar.google.com/citations?user=p-h_BvcAAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Vikas Chandra</a><sup style="color:#6fbf73;">2</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup style="color:#ed4b82;">1</sup>King Abdullah University of Science and Technology</span><br>
              <span class="author-block"><sup style="color:#6fbf73;">2</sup>Meta AI Research</span>
              <span class="author-block"><sup style="color:#ffac33;">3</sup>Korea University</span>
            </div>

                  <div class="content has-text-centered">
                    <div class="publication-links">
                      <span class="link-block">
                        <a href="" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <span class="link-block">
                      <a href="" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                    </span>

                    <span class="link-block">
                      <a href="" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        ðŸ¤—
                      </span>
                      <span>Models</span>
                    </a>
                  </span>
                  </span>


                  <span class="link-block">
                    <a href="" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      ðŸŽ¨
                    </span>
                    <span>Demo</span>
                    </a>
                  </span>

              </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-sixths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Multimodal Large Language Models (MLLMs) have shown promising progress in understanding and analyzing video content. However, processing long videos remains a significant challenge constrained by the limited context length. To address this limitation, we propose <strong>LongVU</strong>, a spatiotemporal adaptive compression mechanism to reduce the number of video tokens while preserving visual details of long videos. Our idea is based on leveraging cross-modal query and inter-frame dependencies to adaptively reduce temporal and spatial redundancy in videos. Specifically, we leverage DINOv2 features to remove redundant frames that exhibit high similarity. Then we utilize text-guided cross-modal query for selective frame feature reduction. Further, we perform spatial token reduction across frames based on their temporal dependencies. Our adaptive compression strategy effectively processes a large number of frames with little visual information loss within limited context length. Our LongVU consistently surpass existing methods across a variety of video understanding benchmarks, especially on hour-long video understanding tasks such as VideoMME and MLVU. Given a light-weight LLM, our LongVU also scales effectively into a smaller size with state-of-the-art video understanding performance.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Examples</h2> <br></div>
  </div></section>

<section class="hero is-small">
  <div class="hero-body">
        <div class="container" style="margin-top: -60px;">
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item">
              <video width="100%" controls style="margin-bottom: 30px;">
                <source src="https://longvu.s3.amazonaws.com/assets/video_10834.mp4" type="video/mp4">
              </video>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 180px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> Can you identify the direction of the yellow sphere's movement in the video?</p>
                <p><strong style="color: #008AD7;">LongVU:</strong> The yellow sphere is moving away from the red cube and towards the right side of the frame.</p>
              </div>
            </div>

            <div class="item">
              <video width="100%" controls style="margin-bottom: 30px;">
                <source src="https://longvu.s3.amazonaws.com/assets/H_H_3_0709_0916.mp4" type="video/mp4">
              </video>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 180px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> What happens to the man as he tries to free himself from the narrow gap in the chair?</p>
                <p><strong style="color: #008AD7;">LongVU:</strong> As the man tries to free himself from the narrow gap in the chair, he gets stuck and struggles to get out.</p>
              </div>
            </div>

            <div class="item">
              <video width="100%" controls style="margin-bottom: 30px;">
                <source src="https://longvu.s3.amazonaws.com/assets/Top081_02555.mp4" type="video/mp4">
              </video>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 180px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> Describe this video in detail.</p>
                <p><strong style="color: #008AD7;">LongVU:</strong> The video begins with a scene featuring two animated characters in a fantastical setting, suggesting a narrative of adventure or conflict. The first character, dressed in a yellow and red martial arts uniform with a mask, is seen in a defensive or preparatory stance, while the second character, an older man with a white beard and a blue robe, appears surprised or concerned. The background is filled with green, leaf-like structures and a mountainous landscape, indicating a natural, possibly magical environment.</p>
              </div>
            </div>

            <div class="item">
              <video width="100%" controls style="margin-bottom: 30px;">
                <source src="https://longvu.s3.amazonaws.com/assets/1E7VU.mp4" type="video/mp4">
              </video>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 180px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> What happened after the person held the dish?</p>
                <p><strong style="color: #008AD7;">LongVU:</strong> After holding the dish, the person placed it in the cabinet.</p>
              </div>
            </div>

          </div>
        </div>
  </div>
</section>

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Long Video Examples</h2> <br></div>
  </div></section>

<section class="hero is-small">
  <div class="hero-body">
        <div class="container" style="margin-top: -60px;">
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item">
              <video width="100%" controls style="margin-bottom: 20px;">
                <source src="https://longvu.s3.amazonaws.com/assets/count_139.mp4" type="video/mp4">
              </video>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 180px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> In this video, how many times does the scene of the 'making jewelry' action appear in total?</p>
                <p><strong style="color: #008AD7;">LongVU:</strong> The scene of the 'making jewelry' action appears twice in the video.</p>
                <p style="color: rgb(168, 71, 71);">(For your reference, the relevant section starts around 00:50 and 03:15)</p>
              </div>
            </div>

            <div class="item">
              <video width="100%" controls style="margin-bottom: 20px;">
                <source src="https://longvu.s3.amazonaws.com/assets/ego_36.mp4" type="video/mp4">
              </video>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 180px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> Who did I interact with when I skated?</p>
                <p><strong style="color: #008AD7;">LongVU:</strong> During your skating, you interacted with a lady wearing a black dress.</p>
                <p style="color: rgb(168, 71, 71);">(For your reference, the relevant section starts around 05:00)</p>
              </div>
            </div>

            <div class="item">
              <video width="100%" controls style="margin-bottom: 20px;">
                <source src="https://longvu.s3.amazonaws.com/assets/needle_43.mp4" type="video/mp4">
              </video>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 180px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> What is the condition of the highway where the SUV is parked for green screen or chroma key?</p>
                <p><strong style="color: #008AD7;">LongVU:</strong> The highway where the SUV is parked for green screen or chroma key is empty and surrounded by trees.</p>
                <p style="color: rgb(168, 71, 71);">(For your reference, the relevant section starts around 17:53)</p>
              </div>
            </div>

            <div class="item">
              <video width="100%" controls style="margin-bottom: 30px;">
                <source src="https://longvu.s3.amazonaws.com/assets/order_160.mp4" type="video/mp4">
              </video>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 180px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> Arrange the following events from the video in the correct chronological order: (1)Woman begins ripping the wrapping paper with her hands; (2)Woman sets the box on top of the wrapping paper and begins wrapping the box; (3)Woman lifts up a box and sets it on the table; (4)Woman grabs a pair of scissors and tape. Options:
                  <ul>
                    (A) 1->2->3->4 (B) 4->3->2->1 (C) 2->1->3->4 (D) 3->4->1->2
                  </ul>
                </p>
                <p><strong style="color: #008AD7;">LongVU:</strong> (D)3->4->1->2.</p>
                <p style="color: rgb(168, 71, 71);">(For your reference, the relevant section starts around 01:15:51)</p>
              </div>
            </div>

            <div class="item">
              <video width="100%" controls style="margin-bottom: 20px;">
                <source src="https://longvu.s3.amazonaws.com/assets/needle_76.mp4" type="video/mp4">
              </video>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 180px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> What is the chef doing with the lobster in the dinner preparation?</p>
                <p><strong style="color: #008AD7;">LongVU:</strong> The chef is cutting the lobster in half.</p>
                <p style="color: rgb(168, 71, 71);">(For your reference, the relevant section starts around 05:37)</p>
              </div>
            </div>

          </div>
        </div>
  </div>
</section>
<!-- End image carousel -->

<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Brief video introduction about <span style="font-weight:bold;">BLINK Benchmark.</span>.
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-sixths">
        <h2 class="title is-3">LongVU Architecture</h2>
        <h2 class="content has-text-justified">
          Architecture of <strong>LongVU</strong>. Given a densely sampled video frames, we first utilize DINOv2 prior to remove redundant frames, and fuse the remaining frame features from both SigLIP and DINOv2. Then we selectively reduce visual tokens via cross-modal query. Finally, we conduct spatial token compression based on temporal dependencies to further meet the limited context length of LLMs.
        </h2>
        <img src="static/images/method.png" height="100%"/>
      </div>
    </div>
  </div>
</section>



<!-- Paper Qualitative -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-sixths">
        <h2 class="title is-3">Video Understanding Results</h2>
        <div class="myrow">
          <img src="static/images/result1.png" height="100%"/>
        </div>

      </div>
    </div>
  </div>
</section>

<!-- Paper Qualitative -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-sixths">
        <h2 class="title is-3">Edge Model Results</h2>
        <div class="myrow">
          <img src="static/images/result2.png" height="100%"/>
        </div>

      </div>
    </div>
  </div>
</section>

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">Citation (BibTeX)</h2><pre><code>
@article{shen2024longvu,
  title={LongVU: Spatiotemporal Adaptive Compression for Long Video-Language Understanding},
  author={},
  journal={},
  year={2024}
  }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page.

          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->

<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
