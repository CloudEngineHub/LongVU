<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="LongVU">

  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Vision-Language Model, Multi-modal LLM, Spatial-Temporal Understanding">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>LongVU</title>
  <link rel="icon" type="image/x-icon" href="static/images/icon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-five-sixths">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">LongVU: Spatiotemporal Adaptive Compression for Long Video-Language Understanding</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <a href="https://xiaoqian-shen.github.io/" style="color:#008AD7;font-weight:normal;">Xiaoqian Shen</a><sup style="color:#6fbf73;">1,</sup><sup style="color:#ed4b82;">2,</sup></sup><sup>*</sup>,</span>
              <a href="https://scholar.google.com/citations?user=k5FaRwcAAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Yunyang Xiong</a><sup style="color:#6fbf73;">1,</sup></sup><sup style="color:#fd3be0;">â˜¨</sup>,</span>
              <a href="https://scholar.google.com/citations?user=bXnrlyAAAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Changsheng Zhao</a><sup style="color:#6fbf73;">1</sup>,</span>
              <a href="https://scholar.google.ca/citations?user=PCDSl2sAAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Lemeng Wu</a><sup style="color:#6fbf73;">1</sup>,</span>
              <a href="https://scholar.google.com/citations?user=9G2OQmkAAAAJ&hl=en&oi=ao" style="color:#008AD7;font-weight:normal;">Jun Chen</a><sup style="color:#ed4b82;">2</sup>,</span>
              <a href="https://scholar.google.com/citations?user=MlyN118AAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Chenchen Zhu</a><sup style="color:#6fbf73;">1</sup>,</span>
              <a href="https://scholar.google.com/citations?user=lA7ylt4AAAAJ&hl=zh-CN" style="color:#008AD7;font-weight:normal;">Zechun Liu</a><sup style="color:#6fbf73;">1</sup>,</span>
              <a href="https://scholar.google.com/citations?user=cuqP0dYAAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Fanyi Xiao</a><sup style="color:#6fbf73;">1</sup>,</span>
              <a href="https://scholar.google.com/citations?user=fCqk928AAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Balakrishnan Varadarajan</a><sup style="color:#6fbf73;">1</sup>,</span>
              <a href="https://scholar.google.com/citations?user=OADfWhUAAAAJ" style="color:#008AD7;font-weight:normal;">Florian Bordes</a><sup style="color:#6fbf73;">1</sup>,</span>
              <a href="https://scholar.google.com/citations?user=7OTD-LEAAAAJ" style="color:#008AD7;font-weight:normal;">Zhuang Liu</a><sup style="color:#6fbf73;">1</sup>,</span>
              <a href="https://scholar.google.com/citations?user=SaH2yWMAAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Hu Xu</a><sup style="color:#6fbf73;">1</sup>,</span>
              <a href="https://scholar.google.com/citations?user=LfBoJt8AAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Hyunwoo J. Kim</a><sup style="color:#ffac33;">3</sup>,</span>
              <a href="https://openreview.net/profile?id=~Bilge_Soran1" style="color:#008AD7;font-weight:normal;">Bilge Soran</a><sup style="color:#6fbf73;">1</sup>,</span>
              <a href="https://scholar.google.com/citations?user=F1mr9C0AAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Raghuraman Krishnamoorthi</a><sup style="color:#6fbf73;">1</sup>,</span>
              <a href="https://scholar.google.com/citations?user=iRBUTOAAAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Mohamed Elhoseiny</a><sup style="color:#ed4b82;">2,</sup><sup style="color:#fd3be0;">â˜¨</sup>,</span>
              <a href="https://scholar.google.com/citations?user=p-h_BvcAAAAJ&hl=en" style="color:#008AD7;font-weight:normal;">Vikas Chandra</a><sup style="color:#6fbf73;">1,</sup><sup style="color:#fd3be0;">â˜¨</sup></span>
            </div>

            <br>

            <div class="is-size-4 publication-authors">
              <span class="author-block"><sup style="color:#6fbf73;">1</sup>Meta AI</span>&nbsp;
              <span class="author-block"><sup style="color:#ed4b82;">2</sup>King Abdullah University of Science and Technology</span>
              <span class="author-block"><sup style="color:#ffac33;">3</sup>Korea University</span>
            </div>

            <div class="is-size-9 publication-authors">
              <span class="author-block"><sup>*</sup>Work done at Meta</span>&nbsp;
              <span class="author-block"><sup style="color:#fd3be0;">â˜¨</sup>Project lead</span>
            </div>

            <br>

                  <div class="content has-text-centered">
                    <div class="publication-links">
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2410.17434" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <span class="link-block">
                      <a href="https://github.com/Vision-CAIR/LongVU" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                    </span>

                    <span class="link-block">
                      <a href="https://huggingface.co/collections/Vision-CAIR/longvu-67181d2debabfc1eb050c21d" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        ðŸ¤—
                      </span>
                      <span>Models</span>
                    </a>
                  </span>
                  </span>


                  <span class="link-block">
                    <a href="https://huggingface.co/spaces/Vision-CAIR/LongVU" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      ðŸŽ¨
                    </span>
                    <span>Demo</span>
                    </a>
                  </span>

              </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="https://longvu.s3.amazonaws.com/assets/combine.mov"
        type="video/mp4">
      </video>

      <script>
        // Wait until the page is loaded
        window.onload = function() {
          // Get the video element by its id
          var video = document.getElementById("tree");

          // Set the default playback speed (e.g., 1.5x speed)
          video.playbackRate = 0.5;
        };
      </script>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-sixths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Multimodal Large Language Models (MLLMs) have shown promising progress in understanding and analyzing video content. However, processing long videos remains a significant challenge constrained by the given context length. To address this limitation, we propose <strong>LongVU</strong>, a spatiotemporal adaptive compression mechanism to reduce the number of video tokens while preserving visual details of long videos. Our idea is based on leveraging cross-modal query and inter-frame dependencies to adaptively reduce temporal and spatial redundancy in videos. Specifically, we leverage DINOv2 features to remove redundant frames that exhibit high similarity. Then we utilize text-guided cross-modal query for selective frame feature reduction. Further, we perform spatial token reduction across frames based on their temporal dependencies. Our adaptive compression strategy effectively processes a large number of frames with little visual information loss within limited context length. Our LongVU consistently surpass existing methods across a variety of video understanding benchmarks, especially on hour-long video understanding tasks such as VideoMME and MLVU. Given a light-weight LLM, our LongVU also scales effectively into a smaller size with state-of-the-art video understanding performance.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Examples</h2> <br></div>
  </div></section>

<section class="hero is-small">
  <div class="hero-body">
        <div class="container" style="margin-top: -60px;">
          <div id="results-carousel" class="carousel results-carousel">

            <div class="item">
              <div style="text-align: center;">
              <video width="70%" controls style="margin-bottom: 30px;">
                <source src="https://longvu.s3.amazonaws.com/assets/robot-video-game.mp4" type="video/mp4">
              </video>
              </div>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 100px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> Please provide a detailed description of the video.</p>
                <p><strong style="color: #008AD7;">LongVU:</strong> The video begins with a scene set in a futuristic cityscape at night, where a humanoid robot stands in the foreground, its back to the camera, against a backdrop of illuminated buildings and a helicopter in flight. The setting is characterized by a blend of modern and cyberpunk elements, with neon signs and a wet street reflecting the city lights. As the video progresses, the robot remains stationary, with the helicopter moving closer, eventually hovering above the street, indicating a possible interaction or event unfolding between the robot and the helicopter.
                  <br><br>
                  The scene then shifts to an interior setting, likely a workshop or garage, filled with various electronic equipment and machinery. The robot is now in the foreground, facing the camera, with a person in the background, suggesting a narrative progression. The environment is cluttered, with the lighting casting a blue hue over the scene, emphasizing the technological theme.
                  <br><br>
                  As the video continues, the camera angle changes to show the robot from behind, with the person in the background now more visible, indicating movement. The workshop setting remains consistent, with the clutter and electronic equipment unchanged. The lighting and color scheme continue to highlight the technological ambiance.
                  <br><br>
                  The perspective then shifts to a side view of the robot, revealing more of its structure and the cluttered workshop environment. The person in the background is now closer to the robot, suggesting interaction or movement towards it. The lighting and color scheme remain consistent, maintaining the technological atmosphere.
                  <br><br>
                  Finally, the camera zooms in on the robot, focusing on its upper body and the intricate details of its internal components. The cluttered workshop environment becomes less visible, with the lighting casting a blue hue over the scene, emphasizing the technological theme. The camera's close-up shot highlights the robot's design and the complexity of its internal mechanisms, suggesting a narrative focus on the robot's internal workings or its role within the technological setting.</p>
              </div>
            </div>

            <div class="item">
              <div style="text-align: center;">
              <video width="70%" controls style="margin-bottom: 30px;">
                <source src="https://longvu.s3.amazonaws.com/assets/sav_000036.mp4" type="video/mp4">
              </video>
              </div>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 100px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> How many toys did the dog play with?</p>
                <p><strong style="color: #008AD7;">LongVU:</strong> The dog played with a total of two toys in the video.</p>
              </div>
            </div>

            <div class="item">
              <div style="text-align: center;">
              <video width="70%" controls style="margin-bottom: 30px;">
                <source src="https://longvu.s3.amazonaws.com/assets/video_10834.mp4" type="video/mp4">
              </video>
              </div>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 100px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> Can you identify the direction of the yellow sphere's movement in the video?</p>
                <p><strong style="color: #008AD7;">LongVU:</strong> The yellow sphere is moving away from the red cube and towards the right side of the frame.</p>
              </div>
            </div>

            <div class="item">
              <div style="text-align: center;">
              <video width="70%" controls style="margin-bottom: 30px;">
                <source src="https://longvu.s3.amazonaws.com/assets/video2.mp4" type="video/mp4">
              </video>
            </div>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 100px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> What is the name of the store?</p>
                <p><strong style="color: #008AD7;">LongVU:</strong> The name of the store is "Animate".</p>
              </div>
            </div>

            <div class="item">
              <div style="text-align: center;">
              <video width="70%" controls style="margin-bottom: 30px;">
                <source src="https://longvu.s3.amazonaws.com/assets/Top081_02555.mp4" type="video/mp4">
              </video>
            </div>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 100px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> Describe this video in detail.</p>
                <p><strong style="color: #008AD7;">LongVU:</strong> The video begins with a scene featuring two animated characters in a fantastical setting, suggesting a narrative of adventure or conflict. The first character, dressed in a yellow and red martial arts uniform with a mask, is seen in a defensive or preparatory stance, while the second character, an older man with a white beard and a blue robe, appears surprised or concerned. The background is filled with green, leaf-like structures and a mountainous landscape, indicating a natural, possibly magical environment.</p>
              </div>
            </div>

            <div class="item">
              <div style="text-align: center;">
              <video width="70%" controls style="margin-bottom: 30px;">
                <source src="https://longvu.s3.amazonaws.com/assets/1E7VU.mp4" type="video/mp4">
              </video>
            </div>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 100px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> What happened after the person held the dish?</p>
                <p><strong style="color: #008AD7;">LongVU:</strong> After holding the dish, the person placed it in the cabinet.</p>
              </div>
            </div>

          </div>
        </div>
  </div>
</section>

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Long Video Examples</h2> <br></div>
  </div></section>

<section class="hero is-small">
  <div class="hero-body">
        <div class="container" style="margin-top: -60px;">
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item">
              <div style="text-align: center;">
              <video width="70%" controls style="margin-bottom: 20px;">
                <source src="https://longvu.s3.amazonaws.com/assets/count_139.mp4#t=3" type="video/mp4">
              </video>
            </div>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 100px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> In this video, how many times does the scene of the 'making jewelry' action appear in total?</p>
                <p><strong style="color: #008AD7;">LongVU:</strong> The scene of the 'making jewelry' action appears twice in the video.</p>
                <p style="color: rgb(168, 71, 71);">(For your reference, the relevant section starts around 00:50 and 03:15)</p>
              </div>
            </div>

            <div class="item">
              <div style="text-align: center;">
              <video width="70%" controls style="margin-bottom: 20px;">
                <source src="https://longvu.s3.amazonaws.com/assets/ego_36.mp4#t=300" type="video/mp4">
              </video>
            </div>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 100px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> Who did I interact with when I skated?</p>
                <p><strong style="color: #008AD7;">LongVU:</strong> During your skating, you interacted with a lady wearing a black dress.</p>
                <p style="color: rgb(168, 71, 71);">(For your reference, the relevant section starts around 05:00)</p>
              </div>
            </div>

            <div class="item">
              <div style="text-align: center;">
              <video width="70%" controls style="margin-bottom: 20px;">
                <source src="https://longvu.s3.amazonaws.com/assets/needle_43.mp4#t=1" type="video/mp4">
              </video>
            </div>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 100px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> What is the condition of the highway where the SUV is parked?</p>
                <p><strong style="color: #008AD7;">LongVU:</strong> The highway where the SUV is parked is empty and surrounded by trees.</p>
                <p style="color: rgb(168, 71, 71);">(For your reference, the relevant section starts around 17:53)</p>
              </div>
            </div>

            <!-- <div class="item">
              <div style="text-align: center;">
              <video width="70%" controls style="margin-bottom: 30px;">
                <source src="https://longvu.s3.amazonaws.com/assets/order_160.mp4" type="video/mp4">
              </video>
            </div>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 100px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> Arrange the following events from the video in the correct chronological order: (1)Woman begins ripping the wrapping paper with her hands; (2)Woman sets the box on top of the wrapping paper and begins wrapping the box; (3)Woman lifts up a box and sets it on the table; (4)Woman grabs a pair of scissors and tape. Options:
                  <ul>
                    <li>(A) 1->2->3->4</li>
                    <li>(B) 4->3->2->1</li>
                    <li>(C) 2->1->3->4</li>
                    <li>(D) 3->4->1->2</li>
                  </ul>
                </p>
                <p><strong style="color: #008AD7;">LongVU:</strong> (D)3->4->1->2.</p>
                <p style="color: rgb(168, 71, 71);">(For your reference, the relevant section starts around 01:15:51)</p>
              </div>
            </div> -->

            <div class="item">
              <div style="text-align: center;">
              <video width="70%" controls style="margin-bottom: 20px;">
                <source src="https://longvu.s3.amazonaws.com/assets/needle_76.mp4#t=337" type="video/mp4">
              </video>
            </div>

              <div class="answer-text" style="font-size: 16px; font-family: 'Arial'; margin-bottom: 20px; max-height: 100px; overflow-y: auto;">
                <p><strong style="color: #ec9720;">User:</strong> What is the chef doing with the lobster in the dinner preparation?</p>
                <p><strong style="color: #008AD7;">LongVU:</strong> The chef is cutting the lobster in half.</p>
                <p style="color: rgb(168, 71, 71);">(For your reference, the relevant section starts around 05:37)</p>
              </div>
            </div>

          </div>
        </div>
  </div>
</section>
<!-- End image carousel -->

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-sixths">
        <h2 class="title is-3">LongVU Architecture</h2>
        <h2 class="content has-text-justified">
          Architecture of <strong>LongVU</strong>. Given a densely sampled video frames, we first utilize DINOv2 prior to remove redundant frames, and fuse the remaining frame features from both SigLIP and DINOv2. Then we selectively reduce visual tokens via cross-modal query. Finally, we conduct spatial token compression based on temporal dependencies to further meet the limited context length of LLMs.
        </h2>
        <img src="static/images/method.png" width="80%"/>
      </div>
    </div>
  </div>
</section>



<!-- Paper Qualitative -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-sixths">
        <h2 class="title is-3">Video Understanding Results</h2>
        <div class="myrow">
          <img src="static/images/result1.png" width="80%"/>
        </div>

      </div>
    </div>
  </div>
</section>

<!-- Paper Qualitative -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-sixths">
        <h2 class="title is-3">Edge Model Results</h2>
        <div class="myrow">
          <img src="static/images/result2.png" width="80%"/>
        </div>

      </div>
    </div>
  </div>
</section>

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">Citation</h2><pre><code>@article{shen2024longvu,
    title={LongVU: Spatiotemporal Adaptive Compression for Long Video-Language Understanding},
    author={Shen, Xiaoqian and Xiong, Yunyang and Zhao, Changsheng and Wu, Lemeng and Chen, Jun and Zhu, Chenchen and Liu, Zechun and Xiao, Fanyi and Varadarajan, Balakrishnan and Bordes, Florian and Liu, Zhuang and Xu, Hu and J. Kim, Hyunwoo and Soran, Bilge and Krishnamoorthi, Raghuraman and Elhoseiny, Mohamed and Chandra, Vikas},
    journal={arXiv:2410.17434},
    year={2024}
  }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page.

          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->

<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
